{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to start, we import the needed python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import glob as gl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import the spreadsheet (.csv) data into python 'pandas' dataframes.\n",
    "\n",
    "Several modifications to the original data were carried out on the data being imported:\n",
    "- Some 'journey' story units (FV 15-18, EP 32-35, OG 63-65) were combined into one since they had been erroneously created as several story units consisting of the same journey. cumulative time stamps were erased to prevent journey segments from rendering on graphs. Refer to clip_time or to original db for reference.\n",
    "- OG story units 39 and 40 to correct time error.\n",
    "- CT: 7 journeys were in original dataset, but only one was retained in atlascine. This is because these 6 other journeys recount movement of others (not the storyteller/protagonist). These journeys were kept in the updated datasets and therefore render on the present graphs.\n",
    "- journey data in the journey field has been manipulated (in cases where journey was applied to only one location for unknown reasons). see original data on private servers for originals.\n",
    "- multi-place story units were left as is (as several story units occurring simultaneously. This means that the total duration (sum) of all story units in a story will exceed the story's running time (e.g. CT).\n",
    "\n",
    "Because this data is public, and certain fields revealed the identity of the storyteller, the following columns have been removed for the current datasets\n",
    "- '*_pm.csv' data sets have columns H-L removed (index 7-10)\n",
    "- '*_su.csv' data sets have columns J, K, and N-W removed (index 9, 10, 13-22)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch story data from csv files stored in /documents and with filename format \"initials_type.csv\" (e.g. og_pm, og_su). Store the fetched data as pandas dataframes inside dictionary d\n",
    "storydata1 = gl.glob('documents_place_mentions/*.csv')\n",
    "storydata2 = gl.glob('documents_story_units/*.csv')\n",
    "d1 = {}\n",
    "d2 = {}\n",
    "\n",
    "#load csvs as dataframes into a dictionary\n",
    "for story in storydata1:\n",
    "    d1[story[25:30]] = pd.read_csv(story, sep=',', encoding='latin-1')\n",
    "\n",
    "for story in storydata2:\n",
    "    d2[story[22:27]] = pd.read_csv(story, sep=',', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data then needs to be cleaned up and organized for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing data with \"null\"\n",
    "def cleanNA(df):\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    df.dropna(axis=0, how='all', inplace=True)\n",
    "    df.fillna('null', inplace=True)\n",
    "\n",
    "#name columns appropriately\n",
    "def renameCols(name, df):\n",
    "    if name[-2:] == 'pm':\n",
    "        df.columns = ['id','session_num','time_clip','time', 'place', 'place_raw','scale']\n",
    "    else:\n",
    "        df.columns = ['id','session_num', 'su_num','time_clip_start', 'time_clip_end', 'time_start', 'time_end', 'place', 'place_raw', 'scale', 'journey']\n",
    "\n",
    "def cleanVals(name, df):\n",
    "    df['scale'] = df.scale.str.lower()\n",
    "    df.loc[df['scale'].str.contains('unknown', case=False), 'scale'] = 'null'\n",
    "    df['scale'].replace('city / area\\n', 'city / area', inplace=True)\n",
    "    #remove rows that are basically empty (make sure there are no actual story units containing no start and end-time, of course, but this should not be the case)\n",
    "    if name[-2:] == 'su':\n",
    "        nullList = df.loc[df['time_start'].str.contains('null', case=False) & df['time_end'].str.contains('null', case=False)].index\n",
    "        for null in nullList:\n",
    "            df.drop(null, inplace=True)\n",
    "    #add more cleaning functions if needed\n",
    "    \n",
    "def timeVals(name, df):\n",
    "    if name[-2:] == 'pm':\n",
    "        df['time'] = pd.to_datetime(df.time, format='%H:%M:%S')\n",
    "    else:\n",
    "        df['time_start'] = pd.to_datetime(df.time_start, format='%H:%M:%S')\n",
    "        df['time_end'] = pd.to_datetime(df.time_end, format='%H:%M:%S')\n",
    "\n",
    "def newCols(name, df):    \n",
    "    if name[-2:] == 'su':\n",
    "        df.loc[df['journey'].str.contains('journey', case=False, na=False), 'scale'] = 'journey' #give scale \"journey\" to units that are journeys\n",
    "    df['scale_order'] = df['scale']\n",
    "    df.loc[df['scale'].str.contains('journey'), 'scale_order'] = '1'\n",
    "    df.loc[df['scale'].str.contains('local'), 'scale_order'] = '3'\n",
    "    df.loc[df['scale'].str.contains('very local'), 'scale_order'] = '2'    \n",
    "    df.loc[df['scale'].str.contains('city / area'), 'scale_order'] = '4'\n",
    "    df.loc[df['scale'].str.contains('region'), 'scale_order'] = '5'\n",
    "    df.loc[df['scale'].str.contains('country'), 'scale_order'] = '6'\n",
    "    df.loc[df['scale'].str.contains('continent'), 'scale_order'] = '7'\n",
    "    df.loc[df['scale'].str.contains('null'), 'scale_order'] = '8'\n",
    "    df['scale_order'] = df.scale_order.astype(int)\n",
    "    \n",
    "for k, v in d1.items():\n",
    "    cleanNA(v)\n",
    "    renameCols(k, v)\n",
    "    cleanVals(k, v)\n",
    "    timeVals(k, v)\n",
    "    newCols(k, v)\n",
    "\n",
    "for k, v in d2.items():\n",
    "    cleanNA(v)\n",
    "    renameCols(k, v)\n",
    "    cleanVals(k, v)\n",
    "    timeVals(k, v)\n",
    "    newCols(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      Haiti\n",
       "1                      Haiti\n",
       "2                     France\n",
       "3                      Haiti\n",
       "4                      Haiti\n",
       "5                      Haiti\n",
       "6                      Haiti\n",
       "7                     France\n",
       "8                     France\n",
       "9              Latin America\n",
       "10                 Venezuela\n",
       "11                     Haiti\n",
       "12                 Venezuela\n",
       "13             Latin America\n",
       "14                     Haiti\n",
       "15                     Haiti\n",
       "16                     Haiti\n",
       "17                     Haiti\n",
       "18                     Haiti\n",
       "19                     Haiti\n",
       "20                       USA\n",
       "21                     Haiti\n",
       "22                     Haiti\n",
       "23                     Haiti\n",
       "24            Jérémie, Haiti\n",
       "25                     Haiti\n",
       "26                     Haiti\n",
       "27     Port-au-Prince, Haiti\n",
       "28                     Haiti\n",
       "29                     Haiti\n",
       "               ...          \n",
       "302                      USA\n",
       "303                    Haiti\n",
       "304                    Haiti\n",
       "305                    Haiti\n",
       "306                    Haiti\n",
       "307                      USA\n",
       "308                    Haiti\n",
       "309                    Haiti\n",
       "310                    Haiti\n",
       "311                    Haiti\n",
       "312                    Haiti\n",
       "313                    Haiti\n",
       "314                    Haiti\n",
       "315    Port-au-Prince, Haiti\n",
       "316                    Haiti\n",
       "317                    Haiti\n",
       "318                    Haiti\n",
       "319                    Haiti\n",
       "320                    Haiti\n",
       "321                   France\n",
       "322                    Haiti\n",
       "323                      USA\n",
       "324           Quebec, Canada\n",
       "325           Quebec, Canada\n",
       "326                      USA\n",
       "327                   France\n",
       "328              Switzerland\n",
       "329                    Haiti\n",
       "330                    Haiti\n",
       "331                    Haiti\n",
       "Name: place, Length: 332, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hello = d1['ap_pm']['place']\n",
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "append() missing 1 required positional argument: 'to_append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-46e245af3606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcreateList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-46e245af3606>\u001b[0m in \u001b[0;36mcreateList\u001b[0;34m(name, df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreateList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_place\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplacelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_place\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#pd.concat([placelist,df_place])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: append() missing 1 required positional argument: 'to_append'"
     ]
    }
   ],
   "source": [
    "placelist = np.array\n",
    "\n",
    "def createList(name, df):\n",
    "    df_place = df['place'].values\n",
    "    placelist.append(df_place)\n",
    "    #pd.concat([placelist,df_place])\n",
    "\n",
    "for k, v in d1.items():\n",
    "    createList(k, v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export to csv (and then move to EXPORT folder!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (k1, v1), (k2, v2) in zip(sorted(d1.items()), sorted(d2.items())):\n",
    "    v1.to_csv(k1 + '.csv', sep=',', index=False, encoding='latin-1')\n",
    "    v2.to_csv(k2 + '.csv', sep=',', index=False, encoding='latin-1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
