{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to start, we import the needed python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "from matplotlib.lines import Line2D\n",
    "import glob as gl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import the spreadsheet (.csv) data into python 'pandas' dataframes.\n",
    "\n",
    "Several modifications to the original data were carried out on the data being imported:\n",
    "- Some 'journey' story units (FV 15-18, EP 32-35, OG 63-65) were combined into one since they had been erroneously created as several story units consisting of the same journey. cumulative time stamps were erased to prevent journey segments from rendering on graphs. Refer to clip_time or to original db for reference.\n",
    "- OG story units 39 and 40 to correct time error.\n",
    "- CT: 7 journeys were in original dataset, but only one was retained in atlascine. This is because these 6 other journeys recount movement of others (not the storyteller/protagonist). These journeys were kept in the updated datasets and therefore render on the present graphs.\n",
    "\n",
    "Because this data is public, and certain fields revealed the identity of the storyteller, the following columns have been removed for the current datasets\n",
    "- '*_pm.csv' data sets have columns H-L removed (index 7-10)\n",
    "- '*_su.csv' data sets have columns J, K, and N-W removed (index 9, 10, 13-22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch story data from csv files stored in /documents and with filename format \"initials_type.csv\" (e.g. og_pm, og_su). Store the fetched data as pandas dataframes inside dictionary d\n",
    "storydata1 = gl.glob('documents_place_mentions/*.csv')\n",
    "storydata2 = gl.glob('documents_story_units/*.csv')\n",
    "i = 0\n",
    "j = 0\n",
    "d1 = {}\n",
    "d2 = {}\n",
    "\n",
    "#load csvs as dataframes into a dictionary\n",
    "for story in storydata1:\n",
    "    d1[story[25:30]] = pd.read_csv(story, sep=',', encoding='latin-1')\n",
    "    i += 1\n",
    "\n",
    "for story in storydata2:\n",
    "    d2[story[22:27]] = pd.read_csv(story, sep=',', encoding='latin-1')\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data then needs to be cleaned up and organized for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing data with \"null\"\n",
    "def cleanNA(df):\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    df.dropna(axis=0, how='all', inplace=True)\n",
    "    df.fillna('null', inplace=True)\n",
    "\n",
    "#name columns appropriately\n",
    "def renameCols(name, df):\n",
    "    if name[-2:] == 'pm':\n",
    "        df.columns = ['id','session_num','time_clip','time', 'place', 'place_raw','scale']\n",
    "    else:\n",
    "        df.columns = ['id','session_num', 'su_num','time_clip_start', 'time_clip_end', 'time_start', 'time_end', 'place', 'place_raw', 'scale', 'journey']\n",
    "\n",
    "def cleanVals(name, df):\n",
    "    df['scale'] = df.scale.str.lower()\n",
    "    df.loc[df['scale'].str.contains('unknown', case=False), 'scale'] = 'null'\n",
    "    df['scale'].replace('city / area\\n', 'city / area', inplace=True)\n",
    "    #remove rows that are basically empty (make sure there are no actual story units containing no start and end-time, of course, but this should not be the case)\n",
    "    if name[-2:] == 'su':\n",
    "        nullList = df.loc[df['time_start'].str.contains('null', case=False) & df['time_end'].str.contains('null', case=False)].index\n",
    "        for null in nullList:\n",
    "            df.drop(null, inplace=True)\n",
    "    #add more cleaning functions if needed\n",
    "    \n",
    "def timeVals(name, df):\n",
    "    if name[-2:] == 'pm':\n",
    "        df['time'] = pd.to_datetime(df.time, format='%H:%M:%S')\n",
    "    else:\n",
    "        df['time_start'] = pd.to_datetime(df.time_start, format='%H:%M:%S')\n",
    "        df['time_end'] = pd.to_datetime(df.time_end, format='%H:%M:%S')\n",
    "\n",
    "def newCols(name, df):    \n",
    "    if name[-2:] == 'su':\n",
    "        df.loc[df['journey'].str.contains('journey', case=False, na=False), 'scale'] = 'journey' #give scale \"journey\" to units that are journeys\n",
    "    df['scale_order'] = df['scale']\n",
    "    df.loc[df['scale'].str.contains('journey'), 'scale_order'] = '1'\n",
    "    df.loc[df['scale'].str.contains('local'), 'scale_order'] = '3'\n",
    "    df.loc[df['scale'].str.contains('very local'), 'scale_order'] = '2'    \n",
    "    df.loc[df['scale'].str.contains('city / area'), 'scale_order'] = '4'\n",
    "    df.loc[df['scale'].str.contains('region'), 'scale_order'] = '5'\n",
    "    df.loc[df['scale'].str.contains('country'), 'scale_order'] = '6'\n",
    "    df.loc[df['scale'].str.contains('continent'), 'scale_order'] = '7'\n",
    "    df.loc[df['scale'].str.contains('null'), 'scale_order'] = '8'\n",
    "    df['scale_order'] = df.scale_order.astype(int)\n",
    "\n",
    "for k, v in d1.items():\n",
    "    cleanNA(v)\n",
    "    renameCols(k, v)\n",
    "    cleanVals(k, v)\n",
    "    timeVals(k, v)\n",
    "    newCols(k, v)\n",
    "\n",
    "for k, v in d2.items():\n",
    "    cleanNA(v)\n",
    "    renameCols(k, v)\n",
    "    cleanVals(k, v)\n",
    "    timeVals(k, v)\n",
    "    newCols(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate some statistics\n",
    "\n",
    "- create new column\n",
    "- calculate number of rows with 'time' val falling between time_start and time_end vals (><)\n",
    "- insert val into new column\n",
    "\n",
    "- create new column\n",
    "- calculate number of rows with 'time' val falling between time_start and time_end vals (><) that have the same 'place' val\n",
    "- insert val into new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cda5f27361b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mcalcStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-cda5f27361b6>\u001b[0m in \u001b[0;36mcalcStats\u001b[0;34m(name1, df1, name2, df2)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_pm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate2num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/emory/Desktop/geomedialab_lifestories_timeseries/venv/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/emory/Desktop/geomedialab_lifestories_timeseries/venv/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/emory/Desktop/geomedialab_lifestories_timeseries/venv/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_loc\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/emory/Desktop/geomedialab_lifestories_timeseries/venv/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2614\u001b[0m                     \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2616\u001b[0;31m                     \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2617\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/emory/Desktop/geomedialab_lifestories_timeseries/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   4072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4073\u001b[0m         \u001b[0;31m# unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4074\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_interleaved_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4075\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4076\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/emory/Desktop/geomedialab_lifestories_timeseries/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_interleaved_dtype\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   5046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5048\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5050\u001b[0m     \u001b[0;31m# only numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/emory/Desktop/geomedialab_lifestories_timeseries/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5048\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5050\u001b[0m     \u001b[0;31m# only numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/emory/Desktop/geomedialab_lifestories_timeseries/venv/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calcStats(name1, df1, name2, df2):\n",
    "    r_pm = range(len(df1.index))\n",
    "    r_su = range(len(df2.index))\n",
    "    \n",
    "    df2['mention_freq'] = 0\n",
    "    df2['mention_index'] = ''\n",
    "    df2['mention_places'] = ''\n",
    "    \n",
    "    df2['mention_match_freq'] = 0\n",
    "    df2['mention_match_index'] = ''\n",
    "    df2['mention_match_places'] = ''\n",
    "    \n",
    "    df2['mention_coarser_match_freq'] = 0\n",
    "    df2['mention_coarser_match_index'] = ''\n",
    "    df2['mention_coarser_match_places'] = ''\n",
    "    \n",
    "    df2['mention_finer_match_freq'] = 0\n",
    "    df2['mention_finer_match_index'] = ''\n",
    "    df2['mention_finer_match_places'] = ''\n",
    "    \n",
    "    for i in r_su:\n",
    "        a = dates.date2num(df2.iloc[i]['time_start'])\n",
    "        b = dates.date2num(df2.iloc[i]['time_end'])\n",
    "        place1 = df2.iloc[i]['place']\n",
    "        x = 0\n",
    "        x1 = ''\n",
    "        x11 = ''\n",
    "        y = 0\n",
    "        y1 = ''\n",
    "        y11 = ''\n",
    "        y2 = 0\n",
    "        y21 = ''\n",
    "        y22 = ''\n",
    "        y3 = 0\n",
    "        y31 = ''\n",
    "        y32 = ''\n",
    "        \n",
    "        for j in r_pm:\n",
    "            c = dates.date2num(df1.iloc[j]['time'])\n",
    "            if (c >= a) and (c <= b):\n",
    "                _id = str(df1.iloc[j]['id'])\n",
    "                place2 = df1.iloc[j]['place']\n",
    "                \n",
    "                x += 1\n",
    "                x1 += (\";\" + _id)\n",
    "                x11 += (\";\" + place2)\n",
    "                if place2 == place1:\n",
    "                    y += 1\n",
    "                    y1 += (\";\" + _id)\n",
    "                    y11 += (\";\" + place2)\n",
    "                elif (place1 in place2) and (place1 != place2):\n",
    "                    y2 += 1\n",
    "                    y21 += (\";\" + _id)\n",
    "                    y22 += (\";\" + place2)\n",
    "                elif (place2 in place1) and (place2 != place1):\n",
    "                    y3 += 1\n",
    "                    y31 += (\";\" + _id)\n",
    "                    y32 += (\";\" + place2)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            df2.iloc[i, df2.columns.get_loc('mention_freq')] = x\n",
    "            df2.iloc[i, df2.columns.get_loc('mention_index')] = x1\n",
    "            df2.iloc[i, df2.columns.get_loc('mention_places')] = x11\n",
    "            \n",
    "            df2.iloc[i, df2.columns.get_loc('mention_match_freq')] = y\n",
    "            df2.iloc[i, df2.columns.get_loc('mention_match_index')] = y1\n",
    "            df2.iloc[i, df2.columns.get_loc('mention_match_places')] = y11\n",
    "            \n",
    "            df2.iloc[i, df2.columns.get_loc('mention_coarser_match_freq')] = y2\n",
    "            df2.iloc[i, df2.columns.get_loc('mention_coarser_match_index')] = y21\n",
    "            df2.iloc[i, df2.columns.get_loc('mention_coarser_match_places')] = y22\n",
    "            \n",
    "            df2.iloc[i, df2.columns.get_loc('mention_finer_match_freq')] = y3\n",
    "            df2.iloc[i, df2.columns.get_loc('mention_finer_match_index')] = y31\n",
    "            df2.iloc[i, df2.columns.get_loc('mention_finer_match_places')] = y32\n",
    "\n",
    "for (k1, v1), (k2, v2) in zip(sorted(d1.items()), sorted(d2.items())):\n",
    "    calcStats(k1, v1, k2, v2)\n",
    "    v1.to_csv(k1 + '.csv', sep=',')\n",
    "    v2.to_csv(k2 + '.csv', sep=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
